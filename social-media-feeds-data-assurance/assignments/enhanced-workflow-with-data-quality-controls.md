# Enhanced Workflow: Data Quality Controls

Login to Control-M and Explore the Domains
==
1. In the [button label="Control-M"](tab-0) tab, log in using the following credentials:
	- Username: `emuser`
	- Password: `password`


Open the Enhanced Social Media Data Feeds Workflow
==
1. In the [button label="Control-M"](tab-0) tab, select the **Planning** domain from the top navigation bar.
2. Open the **Folders and Jobs** tab.
3.  Select the folder: `zzz-social-media-feeds-with-data-quality`
4.  Click **Open Workspace** .
5.  Click **Modify** to exit Read-Only Mode and allow changes to the workspace.

>[!NOTE]
>**Workflow Explanation:**
>
>The workflow begins with zzz-get-feeds, which calls the social-media API and writes the raw feed data into feeds.csv. This raw file is immediately handed off to zzz-data-quality-check, where the Control-M Data Assurance job validates the dataset using the configured monitor and rules.
>
>If the data passes validation, an event triggers zzz-ai-score, a Python job that uploads feeds.csv to Google Gemini, generates deterministic sentiment scores, and writes the enriched results to sentiment_scores.csv.
>
>If the data fails validation, Data Assurance automatically triggers zzz-remediate-data, which applies a filtering rule (likes > 50, comments > 10, shares > 10) to fix or reduce low-quality rows. Once remediation completes, the corrected file is also sent to zzz-ai-score.
>
>After scoring completes, zzz-ai-score-cat reads sentiment_scores.csv, categorizes each row as Approved or Declined based on the sentiment score threshold (≥ 0.75), and produces two categorized outputs: approved.csv and declined.csv.
>
>This workflow demonstrates an end-to-end governed pipeline: ingestion → data quality validation → automated remediation → AI scoring → categorization. It shows how Control-M Data Assurance provides guardrails that prevent bad data from flowing into downstream AI steps, ensuring higher-quality, more reliable outputs.

Run the Enhanced Social Media Data Feeds Workflow
==
1. Click <img src="https://play.instruqt.com/assets/tracks/arqnvuii8xfc/f3959ad50a5d344f71c4e33f4220c350/assets/Oct-02-2025_at_13.36.56-image.png" alt="app-icon" style="display:inline; height:50px; vertical-align:middle;" />  in the top toolbar, then select **Run Workspace** to submit the workflow for execution.
2. In the confirmation pop-up, click **Run**.
3.  Navigate to the **Monitoring** domain.
4. Click **All Active Jobs** and **Open**.
5. Review the output of job execution.


Review Output Files
===
1. In the [button label="Code Editor"](tab-3) tab, review the output files generated by the workflow.

	- `feeds.csv`: This file is created by **zzz-get-feeds** and contains the raw social-media posts pulled directly from the API.
		**However, once Data Assurance is introduced, this file may be modified before AI scoring:**
		- If the Data Assurance job, **zzz-data-quality-check**,  detects issues, **zzz-remediate-data** rewrites this file by filtering out low-quality rows (Likes ≥ 50, and Shares ≥ 10).
		- **Result**: `feeds.csv` may now represent the original dataset or a remediated dataset depending on quality.
	- `sentiment_scores.csv`: This file is generated by **zzz-ai-score**, and includes the fields from feeds.csv plus a new column, Sentiment Score, assigned by the Gemini model. Every row from the feed is scored.
	- `approved.csv`: This file is generated by **zzz-ai-score-cat**, and contains only the rows where the sentiment score is 0.75 or higher, labeled as “Approved.”
	- `declined.csv`: This file is genreated by **zzz-ai-score-cat**, and contains all remaining rows—anything with a sentiment score below 0.75, labeled as “Declined.”

>[!NOTE]
>You will see no data containing Likes ≥ 50, and Shares ≥ 10

Summary
==
